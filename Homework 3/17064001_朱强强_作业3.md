<p align="center">Assignment for Bayesian Analysis</p>
<center>朱强强</center>
<center>17064001</center>
<center>Applied Statistics</center>

**6.1. ** Verify the following identity is true.
$$
\sum_{i=1}^n(y_i-\mu)^2=\sum_{i=1}^n(y_i-\bar{y})^2+n(\bar{y}-\mu)^2
$$
**Solution:**

We can prove that
$$
\sum_{i=1}^n(y_i-\bar{y})(\bar{y}-\mu)=\sum_{i=1}^n(y_i-\bar{y})\cdot\bar{y}=0
$$
Thus,
$$
\begin{align}
\sum_{i=1}^n(y_i-\mu)^2&=\sum_{i=1}^n(y_i-\bar{y}+\bar{y}-\mu)^2\\
&=\sum_{i=1}^n(y_i-\bar{y})^2+2\sum_{i=1}^n(y_i-\bar{y})(\bar{y}-\mu)+n(\bar{y}-\mu)^2\\
&=\sum_{i=1}^n(y_i-\bar{y})^2+n(\bar{y}-\mu)^2
\end{align}
$$


**6.2.** The observed weights (in grams) of 20 pieces of candy randomly sampled from candy-making machines in a certain production area are as follows.

46 58 40 47 47     53 43 48 50 55     49 50 52 56 49     54 51 50 52 50

Assume that weights of types of this type of candy are known to follow a normal distribution, and that the mean weight of candies produced by machines in this area is known to be 51g. We are trying to estimate the variance, which we will now call $\theta$.

1. What is the conjugate family of this type of prior distributions for a normal variance (not precision) when the mean is known?

   **Solution:**

   The joint distribution of $n$ observations modelled as conditionally dependent draws from a normal population with known mean $\mu$ and unknown variance $\theta$.
   $$
   \begin{aligned} p\left(y_{1}, \ldots, y_{n} | \mu, \theta\right) &=\prod_{i=1}^{n} \frac{1}{\sqrt{2 \pi\theta} } \exp \left[-\frac{\left(y_{i}-\mu\right)^{2}}{2 \theta}\right] \\ & \propto \frac{1}{\theta^{\frac{n}{2}}} \exp \left[-\frac{\sum_{i=1}^{n}\left(y_{i}-\mu\right)^{2}}{2 \theta}\right] \end{aligned}
   $$
   Rewrite the joint distribution using $\dfrac{\sum(y_i-\mu)^2}{n}$ represented by the symbol $\nu$, this way:
   $$
   p\left(y | \theta\right) \propto \frac{1}{\theta^{\frac{n}{2}}} \exp \left[-\frac{n \nu}{2 \theta}\right]
   $$
   So the likelihood of $\theta$ is 
   $$
   L\left(\theta ; \mathbf{y}\right) \propto \frac{1}{\theta^{\frac{n}{2}}} \exp \left[-\frac{n v}{2 \theta}\right], 0<\sigma^{2}<\infty
   $$
   Hence, we can easily know that the conjugate family is inverse gamma. A conjugate prior for $\theta$ would be
   $$
   p\left(\theta\right)=\frac{\beta^{\alpha}}{\Gamma \alpha} \frac{1}{\theta^{\alpha+1}} \exp \left(-\frac{\beta}{\theta}\right), \quad 0<\sigma^{2}<\infty
   $$
   

2. Suppose previous experience suggests that the expected value of $\theta$ is 12 and the variance of $\theta$ is 4. What parameter values are needed for the prior distribution to match these moments?

   **Solution:**

   From the properties of the inverse gamma distribution, we know that $\dfrac{\beta}{\alpha-1}=12, \alpha>1$ and $\dfrac{\beta^{2}}{(\alpha-1)^{2}(\alpha-2)}=4, \alpha>2$.

   Thus, $\alpha=38$ and $\beta=444$.

   

3. What is the posterior distribution $p(\theta|y)$ for these data under the prior from the previous step?

   **Solution:**
   $$
   \begin{aligned} p\left(\theta | \mathbf{y}\right) & \propto \frac{1}{\theta^{\alpha+1}} \exp \left(-\frac{\beta}{\theta}\right) \times \frac{1}{\left(\theta\right)^{\frac{n}{2}}} \exp \left[-\frac{n\nu}{2 \theta}\right]\\ & \propto \frac{1}{\left(\theta\right)^{\frac{n}{2}+\alpha+1}} \exp \left[-\frac{1}{\theta}\left(\frac{n \nu}{2}+\beta\right)\right]\end{aligned}
   $$
   

4. Find the posterior mean and variance of $\theta$.

   **Solution:**

   From the previous step, we know that the kernel function is 
   $$
   \theta | \mathbf{y} \sim I G\left(\alpha+\frac{n}{2}, \beta+\frac{n \nu}{2}\right)
   $$
   Thus, 

   the mean of $\theta$ is $\dfrac{\beta+\frac{n \nu}{2}}{\alpha+\frac{n}{2}-1}$

   the variance of $\theta$ is $\dfrac{(\beta+\frac{n \nu}{2})^2}{(\alpha+\frac{n}{2}-1)^2(\alpha+\frac{n}{2}-2)}$

   

5. Comment on whether the assumptions of known mean or known variance are likely to be justified in the situation in Problem 6.1.

   **Solution:**

   Real-world problems nearly always require statistical models with more than one unknown quantity. So these assumptions of known mean or known variance are not justified in realistic problems.



**6.3.** Consider two random variables $X$ and $Y$, $0<X,Y<\infty$, where $Y=\dfrac{1}{X}$. Show that $X\sim Gamma(\alpha,\beta)$, then $Y\sim IG(\alpha,\beta)$, $0<X,Y<\infty$.

**Solution:**

If $X\sim Gamma(\alpha,\beta)$, then $p(x | \alpha, \beta)=\dfrac{\beta^{\alpha}}{\Gamma \alpha} x^{\alpha-1} \exp (-\beta x)$.

Since $Y=\dfrac{1}{Y}$, $p(y|\alpha,\beta)=\dfrac{\beta^{\alpha}}{\Gamma \alpha} \dfrac{1}{y^{\alpha-1}} \exp (-\dfrac{\beta}{y})\cdot\left|-\dfrac{1}{y^2}\right|=\dfrac{\beta^{\alpha}}{\Gamma \alpha} \dfrac{1}{y^{\alpha+1}} \exp (-\dfrac{\beta}{y})$

It is the density of an inverse gamma distribution.

Therefore, $Y\sim IG(\alpha,\beta)$.



**7.1.** Reanalyse the candy-weight data from Problem 6.2. This time, acknowledge that both $\mu$ and $\sigma^2$ are unknown, and use the standard noninformative prior given in (7.1).

1. Find $p(\mu|\mathbf{y})$, the posterior marginal density of $\mu$. Name it; give the values of its parameters, and use it to find the posterior mean and 95% credible set for $\mu$.

   **Solution:**

   The standard noninformative prior is:
   $$
   p\left(\mu, \sigma^{2}\right) \propto \frac{1}{\sigma^{2}}, \quad-\infty<\mu<\infty, 0<\sigma^{2}<\infty
   $$
   With observed data vector $\mathbf{y}$, the joint posterior is proportional to
   $$
   \begin{aligned} p\left(\mu, \sigma^{2} | \mathbf{y}\right) & \propto p\left(\mu, \sigma^{2}\right) \times p\left(\mathbf{y} | \mu, \sigma^{2}\right) \\ & \propto \frac{1}{\sigma^{2}} \times \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}}} \exp \left(-\frac{1}{2 \sigma^{2}} \sum_{i=1}^{n}\left(y_{i}-\mu\right)^{2}\right) \\ &=\frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{1}{2 \sigma^{2}}\left[\sum_{i=1}^{n}\left(y_{i}-\bar{y}\right)^{2}+n(\bar{y}-\mu)^{2}\right]\right) \\ &=\frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{1}{2 \sigma^{2}}\left[(n-1) s^{2}+n(\bar{y}-\mu)^{2}\right]\right) \end{aligned}
   $$
   where $s^2$ is the sample variance of $y_i$s, calculated as $s^2=\dfrac{1}{n-1}\sum_{i=1}^n(y_i-\bar{y})^2$.

   We know that
   $$
   p\left(\mu, \sigma^{2} | \mathbf{y}\right)=p\left(\mu | \sigma^{2}, \mathbf{y}\right) p\left(\sigma^{2} | \mathbf{y}\right)
   $$
   Then we simply integrate $\mu$ and identify the kernel of a density:
   $$
   \begin{aligned} p\left(\sigma^{2} | \mathbf{y}\right) & \propto \int_{-\infty}^{\infty} \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{1}{2 \sigma^{2}}\left[(n-1) s^{2}+n(\bar{y}-\mu)^{2}\right]\right) d \mu \\ & \propto \frac{1}{\left(\sigma^{2}\right)^{\frac{n+1}{2}}} \exp \left(-\frac{(n-1) s^{2}}{2 \sigma^{2}}\right) \int_{-\infty}^{\infty} \frac{1}{\sigma} \exp \left(-\frac{n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) d \mu \\  & \propto \frac{1}{\left(\sigma^{2}\right)^{\frac{n+1}{2}}} \exp \left(-\frac{(n-1) s^{2}}{2 \sigma^{2}}\right) \end{aligned}
   $$
   The posterior distribution of $\mu$ with known variance and a flat prior on $\mu$:
   $$
   \mu | \sigma^{2}, \mathbf{y} \sim N\left(\bar{y}, \frac{\sigma^{2}}{n}\right)
   $$
   So the normalized joint posterior distribution is the product:
   $$
   \begin{aligned} p\left(\mu, \sigma^{2} | \mathbf{y}\right)=& \frac{\left(\frac{(n-1) s^{2}}{2}\right)^{\frac{n-1}{2}}}{\Gamma\left(\frac{n-1}{2}\right)} \frac{1}{\left(\sigma^{2}\right)^{\frac{n+1}{2}}} \exp \left(-\frac{(n-1) s^{2}}{2 \sigma^{2}}\right) \times \\ & \frac{\sqrt{n}}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) \end{aligned}
   $$
   Then,
   $$
   \begin{align}
   p(\mu|\mathbf{y})&=\int{\frac{\left(\frac{(n-1) s^{2}}{2}\right)^{\frac{n-1}{2}}}{\Gamma\left(\frac{n-1}{2}\right)} \frac{1}{\left(\sigma^{2}\right)^{\frac{n+1}{2}}} \exp \left(-\frac{(n-1) s^{2}}{2 \sigma^{2}}\right) \times}{\frac{\sqrt{n}}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right)}d\sigma^2\\&{=\frac{\left(\frac{(n-1) s^{2}}{2}\right)^{\frac{n-1}{2}}}{\Gamma\left(\frac{n-1}{2}\right)} \frac{\sqrt{n}}{\sqrt{2 \pi}} \int \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) d \sigma^{2}} \\ &{=\frac{\left(\frac{(n-1) s^{2}}{2}\right)^{\frac{n-1}{2}}}{\Gamma\left(\frac{n-1}{2}\right)} \frac{\sqrt{n}}{\sqrt{2 \pi}} \frac{\Gamma\left(\frac{n}{2}\right)}{\left[\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2}\right]^{\frac{n}{2}}}} \\ &{=\frac{\left(\frac{(n-1) s^{2}}{2}\right)^{\frac{n-1}{2}}}{\Gamma\left(\frac{n-1}{2}\right)} \frac{\sqrt{n}}{\sqrt{2 \pi}} \frac{\Gamma\left(\frac{n}{2}\right)}{\left(\frac{(n-1) s^{2}}{2}\right)^{n / 2}\left[1+\frac{1}{(n-1)}\left(\frac{\mu-\bar{y}}{s / \sqrt{n}}\right)^{2}\right]^{n / 2}}} \\ &{=\frac{\Gamma\left(\frac{n}{2}\right)}{\Gamma\left(\frac{n-1}{2}\right) \sqrt{(n-1) \pi} s / \sqrt{n}\left[1+\frac{1}{(n-1)}\left(\frac{\mu-\bar{y}}{s / \sqrt{n}}\right)^{2}\right]^{n / 2}}}
   \end{align}
   $$
   We know that the pdf of a student's $t$ distributions is 
   $$
   p\left(y | \mu, \sigma^{2}, \nu\right)=\frac{\Gamma\left(\frac{\nu+1}{2}\right)}{\Gamma\left(\frac{\nu}{2}\right) \sqrt{\nu \pi \sigma^{2}}} \frac{1}{\left(1+\frac{1}{\nu}\left(\frac{y-\mu}{\sigma}\right)^{2}\right)^{\frac{\nu+1}{2}}}
   $$
   So the result is a $t$ distribution with

   * mean: $\bar{y}$
   * scale parameter ($\sigma^2$): $\dfrac{s^2}{n}$
   * degrees of freedom ($\nu$): $n-1$ 

   From the results calculated by R, the sample mean $\bar{y}=50$,  the sample variance $s^2=18.31579$, and the sample size $n=20$. Thus, the marginal posterior density of $\mu$ is 
   $$
   \mu|\mathbf{y}\sim t_{19}(50, 0.9157895)
   $$
   A 95% credible set for $\mu$ is [47.99704, 52.00296].

```r
da <- c(46, 58, 40, 47, 47, 53, 43, 48, 50, 55, 49, 50, 52, 56, 49, 
        54, 51, 50, 52, 50)
mean_da <- mean(da)
print(mean_da)
size_da <- length(da)
print(size_da)
sample_variance_da <- var(da) / size_da
print(sample_variance_da)
mean_da + qt(c(0.025, 0.975), 19) * sqrt(sample_variance_da)
t.test(da)
```



2. Suppose that the population variance $\sigma^2$ was the parameter of primary interest. Find its posterior marginal density. Give numeric values of the posterior mean $E(\sigma^2|\mathbf{y})$ and the 95% posterior credible set for $\sigma^2$.

   **Solution:**

   According to the conclusion proved in the first section we know that
   $$
   \sigma^2|\mathbf{y}\sim IG\left(\dfrac{n-1}{2},\dfrac{(n-1)s^2}{2}\right)
   $$
   From the result computed by R we can know that $\sigma^2|\mathbf{y}\sim IG(9.5, 174)$, the posterior mean $E(\sigma^2|\mathbf{y})=20.47059$, and a 95% posterior credible set for $\sigma$ is [10.59286, 39.07252].

```R
alpha <- (size_da - 1) / 2
print(alpha)
beta <- (size_da - 1) * sample_variance_da / 2
print(beta)
mean_IG <- beta / (alpha - 1)
print(mean_IG)
1 / qgamma(c(0.975, 0.025), 9.5, 174)
```



**7.2.** Repeat Problem 7.1 using the conjugate prior from Sect. 7.3. Use the same inverse gamma prior for $\sigma^2$ that you used in Problem 6.2. For the conditional normal prior on $\mu$, specify a mean of 51 and an equivalent prior sample size of 10.

1. Find the joint posterior density as a product of two densities. Give numeric values
   of their parameters.

   **Solution:**

   The conjugate joint prior density—the normal-inverse gamma density—is constructed as the product of a marginal inverse gamma prior density on $\sigma^2$ and a conditional normal density for $\mu$ given $\sigma^2$:
   $$
   \begin{aligned} 
   p\left(\mu, \sigma^{2}\right) &=p\left(\sigma^{2}\right) p\left(\mu | \sigma^{2}\right)=I G(\alpha, \beta) \times N\left(\mu_{0}, \frac{1}{\kappa} \sigma^{2}\right) \\
   &=\frac{\beta^{\alpha}}{\Gamma(\alpha)} \frac{1}{\left(\sigma^{2}\right)^{\alpha+1}} \exp \left(-\frac{\beta}{\sigma^{2}}\right) \times \frac{\sqrt{\kappa}}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{n\left(\mu-\mu_{0}\right)^{2}}{2 \sigma^{2}}\right)
   \end{aligned}
   $$
   Th us,
   $$
   \begin{aligned} p\left(\mu, \sigma^{2} | \mathbf{y}\right) \propto & \frac{1}{\left(\sigma^{2}\right)^{\alpha+1}} \exp \left(-\frac{\beta}{\sigma^{2}}\right) \times \frac{\sqrt{\kappa}}{\sqrt{2 \pi \sigma^{2}}} \exp \left(-\frac{\kappa\left(\mu-\mu_{0}\right)^{2}}{2 \sigma^{2}}\right) \times \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}}} \exp \left(-\frac{(n-1) s^{2}}{2 \sigma^{2}}\right) \dfrac{\sqrt{n}}{\sigma} \exp \left(-\frac{n(\bar{y}-\mu)^{2}}{2 \sigma^{2}}\right) \\ \propto & \frac{1}{\left(\sigma^{2}\right)^{\alpha+\frac{n}{2}+1}} \exp \left(-\frac{1}{\sigma^{2}}\left(\beta+\frac{(n-1) s^{2}}{2}\right)\right) \times \frac{\sqrt{\kappa}}{\sigma} \exp \left(-\frac{\kappa\left(\mu-\mu_{0}\right)^{2}+n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) \end{aligned}
   $$
   In addition,
   $$
   \kappa\left(\mu-\mu_{0}\right)^{2}+n(\mu-\bar{y})^{2} =(\kappa+n)\left(\mu-\frac{\kappa \mu_{0}+n \bar{y}}{\kappa+n}\right)^{2}+\frac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{\kappa+n}
   $$
   Finally,
   $$
   \begin{aligned} p\left(\mu, \sigma^{2} | \mathbf{y}\right) \propto & \frac{1}{\left(\sigma^{2}\right)^{\alpha+\frac{n}{2}+1}} \exp \left[-\frac{1}{\sigma^{2}}\left(\beta+\frac{(n-1) s^{2}}{2}+\frac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{2(\kappa+n)}\right)\right] \times \frac{\sqrt{\kappa}}{\sigma} \exp \left[-(\kappa+n)\left(\frac{\left(\mu-\frac{\kappa \mu_{0}+n \bar{y}}{\kappa+n}\right)^{2}}{2 \sigma^{2}}\right)\right] & \end{aligned}
   $$
   From the above equality we can recognize the joint posterior density as normal-inverse gamma:
   $$
   \begin{array}{c}{\mu, \sigma^{2} | \mathbf{y} \sim I G\left(\alpha+\dfrac{n}{2}, \beta+\dfrac{(n-1) s^{2}}{2}+\dfrac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{2(\kappa+n)}\right) \times} {N\left(\dfrac{\kappa \mu_{0}+n \bar{y}}{\kappa+n}, \dfrac{\sigma^{2}}{\kappa+n}\right)}\end{array}
   $$
   The parameters of the inverse gamma density can be thought of as $\alpha=\dfrac{n_0}{2}$ and $\beta=\dfrac{n_0\sigma_0^2}{2}$. With that reparameterization, the joint posterior density becomes
   $$
   \begin{aligned} \mu, \sigma^{2} | \mathbf{y} \sim & I G\left(\frac{n_{0}}{2}+\frac{n}{2}, \frac{n_{0} \sigma_{0}^{2}}{2}+\frac{(n-1) s^{2}}{2}+\frac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{2(\kappa+n)}\right) \times N\left(\frac{\kappa \mu_{0}+n \bar{y}}{\kappa+n}, \frac{\sigma^{2}}{\kappa+n}\right) \end{aligned}
   $$
   We have already computed that $\alpha=38$ and $\beta=444$.

   $\mu_0=51,\kappa=10,n=20,n_0=2\alpha=76,\bar{y}=50,s^2=18.31579,\sigma_0^2=\dfrac{2\beta}{n_0}=11.68$.

   

2. Find $p(\mu|\mathbf{y})$, the posterior marginal density of $\mu$. Name it; give the values of its parameters; and use it to find the posterior mean and 95% credible set for $\mu$.

   **Solution:**

   The posterior marginal density $p(\mu|\mathbf{y})$ is a $t$ density with:

   * mean $\dfrac{\kappa\mu_0+n\bar{y}}{\kappa+n}=50.33$
   * scale parameter $\dfrac{n_{0} \sigma_{0}^{2}+(n-1) s^{2}+\dfrac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{(\kappa+n)}}{(\kappa+n)\left(n_{0}+n\right)}=0.4314$

   * degrees of freedom $n+n_0=96$

   $$
   \mu|\mathbf{y}\sim t_{96}(50.33, 0.4314)
   $$

   A 95% credible set for $\mu$ is [49.02624, 51.63376].

   ```R
   50.33 + qt(c(0.025, 0.975), 96) * sqrt(0.4314)
   ```

   

3. Suppose that the population variance $\sigma^2$ was the parameter of primary interest. Find its posterior marginal density. Give numeric values of the posterior mean $E(\sigma^2|\mathbf{y})$ and the 95% posterior credible set for $\sigma^2$.

   **Solution:**

   We can find that the posterior marginal density $p(\sigma^2|\mathbf{y})$ is a inverse gamma density.
   $$
   \mu | \mathbf{y} \sim I G\left(\alpha+\frac{n}{2}, \beta+\frac{(n-1) s^{2}}{2}+\frac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{2(\kappa+n)}\right)
   $$
   $\alpha+\dfrac{n}{2}=48\\ \beta+\dfrac{(n-1) s^{2}}{2}+\dfrac{\kappa n\left(\bar{y}-\mu_{0}\right)^{2}}{2(\kappa+n)}=621.33\\ \therefore\mu | \mathbf{y} \sim IG(48,621.33),\quad E(\sigma^2|\mathbf{y})=13.22$

   The 95% posterior credible set for $\sigma^2$ is [9.941274, 17.555955].

```R
1 / qgamma(c(0.975, 0.025), 48, 621.33)
```



**7.3.** Show that the normal-inverse gamma prior produces the conventional noninformative prior if $n_0$ goes to $-1$ and $\kappa$ and $\sigma_0^2$ both go to 0.

**Solution:**

If $n_0$ goes to -1 and $\kappa$ and $\sigma_0^2$ both go to 0, then
$$
\mu,\sigma^2|\mathbf{y}\sim IG\left(\dfrac{n-1}{2},\dfrac{(n-1)s^2}{2}\right)\times N\left(\bar{y},\dfrac{\sigma^2}{n}\right)
$$
It is also the format of the conventional noninformative prior.

Since in the section 7.1.1 we know that the conventional noninformative prior can get
$$
\begin{aligned} p\left(\mu, \sigma^{2} | \mathbf{y}\right)=& \frac{\left(\frac{(n-1) s^{2}}{2}\right)^{\frac{n-1}{2}}}{\Gamma\left(\frac{n-1}{2}\right)} \frac{1}{\left(\sigma^{2}\right)^{\frac{n+1}{2}}} \exp \left(-\frac{(n-1) s^{2}}{2 \sigma^{2}}\right) \times \frac{\sqrt{n}}{\sqrt{2 \pi} \sigma} \exp \left(-\frac{n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) \end{aligned}
$$


**7.4.** Fill in the details of the integration in 7.6. Be sure to explain how line 3 was obtained from line 2.

**Solution:**

We can easily find that $\dfrac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\dfrac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) $ is a format of  the kernel of inverse gamma distribution where $\alpha=\dfrac{n}{2}$ and $\beta=\dfrac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2}$.

Thus,
$$
\begin{aligned}
&\frac{[\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2}]^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)} \ \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right)\sim IG(\dfrac{n}{2}, \dfrac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2}) \\
&\int \frac{[\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2}]^{\frac{n}{2}}}{\Gamma\left(\frac{n}{2}\right)} \ \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) d \sigma^{2}=1
\end{aligned}
$$
Finally,
$$
\int \frac{1}{\left(\sigma^{2}\right)^{\frac{n}{2}+1}} \exp \left(-\frac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2 \sigma^{2}}\right) d \sigma^{2}=\dfrac{\Gamma\left(\frac{n}{2}\right)}{\left[\dfrac{(n-1) s^{2}+n(\mu-\bar{y})^{2}}{2}\right]^{\frac{n}{2}}}
$$


